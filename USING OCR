
from __future__ import unicode_literals
import imutils
import os
import pytesseract
from matplotlib import pyplot as plt
import imutils
import glob
from PIL import Image

import subprocess
import win32com.client as wincl
import time
import glob
import random
import sys
import random
import math
import json
from collections import defaultdict

from PIL import Image, ImageDraw
import numpy as np
from scipy.ndimage.filters import rank_filter

import cv2

#process
image=cv2.imread('obj.jpg')
gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
#cv2.imshow('gray',gray)
#cv2.waitKey(0)
#blur = cv2.GaussianBlur(gray,(5,5),0)
#cv2.imwrite("blur.jpg",blur)
ret,thresh=cv2.threshold(gray,127,255,cv2.THRESH_BINARY_INV)
#cv2.imshow('second',thresh)
#cv2.waitKey(0)

kernel=np.ones((30,30),np.uint8)
img_dilation=cv2.dilate(thresh,kernel,iterations=1)
#cv2.imshow('dilated',img_dilation)
#cv2.waitKey(0)
img_erosion=cv2.erode(img_dilation,kernel,iterations=1)
cv2.imshow('erode',img_erosion)
w=cv2.imread('thresholdImage.png')
_,ctrs,hierarchy=cv2.findContours(img_erosion.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)

sorted_ctrs=sorted(ctrs,key=lambda ctr: cv2.minAreaRect(ctr)[1])

for i,ctr in enumerate(sorted_ctrs):

    x,y,w,h=cv2.boundingRect(ctr)

    roi=image[y:y+h,x:x+w]

    cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)

    if w>10 and h>10:
        cv2.imwrite('{}.png'.format(i),roi)
        #cv2.imshow('marked areas',image)
        #cv2.waitKey(0)

# initialize a rectangular and square structuring kernel
rectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (55,25))
sqKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 20))
# load the image, resize it, and convert it to grayscale
image = cv2.imread('0.png')
#image = imutils.resize(image, height=800)
#gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
cv2.imwrite("gr.png",image)
# smooth the image using a 3x3 Gaussian, then apply the blackhat
# morphological operator to find dark regions on a light background
gray = cv2.GaussianBlur(gray, (3, 3), 0)
blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, rectKernel)
cv2.imwrite("bh.png",blackhat)
# compute the Scharr gradient of the blackhat image and scale the
# result into the range [0, 255]
gradX = cv2.Sobel(blackhat, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=-1)
gradX = np.absolute(gradX)
(minVal, maxVal) = (np.min(gradX), np.max(gradX))
gradX = (255 * ((gradX - minVal) / (maxVal - minVal))).astype("uint8")
cv2.imwrite("sblx.png",gradX)
img = cv2.imread('sblx.png', 0)

kernel = np.ones((3,3), np.uint8)
img_erosion = cv2.erode(img, kernel, iterations=1)
cv2.imwrite("erosion1.png",img_erosion)
#opening
imgo = cv2.imread('erosion1.png',0)
opening = cv2.morphologyEx(imgo, cv2.MORPH_OPEN, kernel)
cv2.imwrite("opened1.png",opening)
#dilate
opening=cv2.imread('opened1.png',0)
img_dilation=cv2.dilate(opening,kernel,iterations=1)
cv2.imwrite("dilation1.png",img_dilation)
#closing
imgo = cv2.imread('dilation1.png',0)
closed1 = cv2.morphologyEx(imgo, cv2.MORPH_CLOSE, kernel)
cv2.imwrite("closed1.png",closed1)

# apply a closing operation using the rectangular kernel to close
# gaps in between letters -- then apply Otsu's thresholding method
gradX = cv2.morphologyEx(gradX, cv2.MORPH_CLOSE, rectKernel)
thresh = cv2.threshold(gradX, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]
cv2.imwrite("thh.png",thresh)
# perform another closing operation, this time using the square
# kernel to close gaps between lines of the MRZ, then perform a
# serieso of erosions to break apart connected components
thresh1 = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, sqKernel)
thresh1 = cv2.erode(thresh, None, iterations=4)
cv2.imwrite("thhh.png",thresh1)
_, contours, _ = cv2.findContours(thresh1.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)
total = 0
print("num of contours: {}".format(len(contours)))
                
              


# during thresholding, it's possible that border pixels were
# included in the thresholding, so let's set 5% of the left and
# right borders to zero
p = int(image.shape[1] * 0.009)
thresh[:, 0:p] = 0
thresh[:, image.shape[1] - p:] = 0
# find contours in the thresholded image and sort them by their
# size
cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,
cv2.CHAIN_APPROX_SIMPLE)[-2]
cnts = sorted(cnts, key=cv2.contourArea, reverse=True)

# loop over the contours
for i,c in enumerate(cnts):
       # compute the bounding box of the contour and use the contour to
       # compute the aspect ratio and coverage ratio of the bounding box
       # width to the width of the image
       (x, y, w, h) = cv2.boundingRect(c)
       roi=image[y:y+h,x:x+w]
       cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)
       if w>10 and h>10:
               cv2.imwrite('{}.png'.format(i),roi)
               #cv2.imshow('marked areas',image)
               #cv2.waitKey(0)

       
   

       print(x)
       ar = w / float(h)
       crWidth = w / float(gray.shape[1])
       if ar>5 and crWidth>0.75:
           pX=int((x+w)*0.01)
           pY=int((y+h)*0.01)
           (x,y)=(x-pX,y-pY)
           (w,h)=(w+(pX*2),h+(pY*2))
           roi=image[y:y+h,x:x+w].copy()
           cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)
           break
#cv2.imshow("Image",image)
#cv2.imshow("ROI",roi)
#cv2.waitKey(0)



            
            
